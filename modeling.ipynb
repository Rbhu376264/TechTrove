{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling for Ozone Variability Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./final_data/alldata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Arithmetic Mean'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data['Date Local'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by=['Site Num', 'Date Local'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = [\n",
    "    'Arithmetic Mean', \n",
    "    'Arithmetic Mean_press', \n",
    "    'Arithmetic Mean_temp', \n",
    "    'Arithmetic Mean_rhdp', \n",
    "    'Arithmetic Mean_winddirection', \n",
    "    'Arithmetic Mean_windspeed'\n",
    "]\n",
    "\n",
    "# Count the number of valid (non-NA) values for each of the specified columns\n",
    "valid_counts = data[columns_to_check].count()\n",
    "\n",
    "valid_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['Arithmetic Mean', 'Arithmetic Mean_temp',  \n",
    "                    'Arithmetic Mean_rhdp', 'Arithmetic Mean_winddirection', 'Arithmetic Mean_windspeed']\n",
    "\n",
    "data = data.dropna(subset=columns_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./final_data/nopress_andna.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with all values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./final_data/nopress_andna.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_counts = data['Local Site Name'].value_counts()\n",
    "row_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_preserve = [\n",
    "    'Date Local',\n",
    "    'Arithmetic Mean',  \n",
    "    'Arithmetic Mean_temp', \n",
    "    'Arithmetic Mean_rhdp', \n",
    "    'Arithmetic Mean_winddirection', \n",
    "    'Arithmetic Mean_windspeed'\n",
    "]\n",
    "\n",
    "min_data = data[columns_to_preserve]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_data.to_csv('./final_data/new_min_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_data.hist(bins=50, figsize=(15, 10))\n",
    "\n",
    "# Display the histograms\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define features and target\n",
    "features = [\n",
    "    'Arithmetic Mean_temp', \n",
    "    'Arithmetic Mean_rhdp', \n",
    "    'Arithmetic Mean_winddirection', \n",
    "    'Arithmetic Mean_windspeed'\n",
    "]\n",
    "\n",
    "X = min_data[features]\n",
    "y = min_data['Arithmetic Mean']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training (70%), development (10%), and test (20%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=2/3, random_state=42)\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "rf_param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Random search of parameters for Random Forest\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=rf_param_dist, \n",
    "                               n_iter=50, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the Random Forest model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best Random Forest model on the development set\n",
    "best_rf = rf_random.best_estimator_\n",
    "rf_dev_pred = best_rf.predict(X_dev)\n",
    "rf_dev_rmse = mean_squared_error(y_dev, rf_dev_pred, squared=False)\n",
    "rf_dev_r2 = r2_score(y_dev, rf_dev_pred)\n",
    "\n",
    "# Define the parameter grid for SVM\n",
    "svm_param_dist = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Create a Support Vector Machine Regressor\n",
    "svm = SVR()\n",
    "\n",
    "# Random search of parameters for SVM\n",
    "svm_random = RandomizedSearchCV(estimator=svm, param_distributions=svm_param_dist, \n",
    "                                n_iter=50, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the SVM model\n",
    "svm_random.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best SVM model on the development set\n",
    "best_svm = svm_random.best_estimator_\n",
    "svm_dev_pred = best_svm.predict(X_dev)\n",
    "svm_dev_rmse = mean_squared_error(y_dev, svm_dev_pred, squared=False)\n",
    "svm_dev_r2 = r2_score(y_dev, svm_dev_pred)\n",
    "\n",
    "# Print only the metrics typically necessary for a research paper for the best models\n",
    "print(\"Random Forest - Development RMSE:\", rf_dev_rmse, \"Development R^2:\", rf_dev_r2)\n",
    "print(\"Support Vector Machine - Development RMSE:\", svm_dev_rmse, \"Development R^2:\", svm_dev_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_rf)\n",
    "print(best_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize Linear Regression and Ridge Regression models\n",
    "lr_model = LinearRegression()\n",
    "ridge_model = Ridge()\n",
    "\n",
    "# Train Linear Regression model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the development set\n",
    "lr_dev_pred = lr_model.predict(X_dev)\n",
    "\n",
    "# Calculate RMSE and R^2 for Linear Regression on the development set\n",
    "lr_dev_rmse = mean_squared_error(y_dev, lr_dev_pred, squared=False)\n",
    "lr_dev_r2 = r2_score(y_dev, lr_dev_pred)\n",
    "\n",
    "# Train Ridge Regression model\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the development set\n",
    "ridge_dev_pred = ridge_model.predict(X_dev)\n",
    "\n",
    "# Calculate RMSE and R^2 for Ridge Regression on the development set\n",
    "ridge_dev_rmse = mean_squared_error(y_dev, ridge_dev_pred, squared=False)\n",
    "ridge_dev_r2 = r2_score(y_dev, ridge_dev_pred)\n",
    "\n",
    "# Print the evaluation metrics for Linear Regression\n",
    "print(\"Linear Regression - Development RMSE:\", lr_dev_rmse, \"Development R^2:\", lr_dev_r2)\n",
    "\n",
    "# Print the evaluation metrics for Ridge Regression\n",
    "print(\"Ridge Regression - Development RMSE:\", ridge_dev_rmse, \"Development R^2:\", ridge_dev_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the Random Forest model with the specified parameters\n",
    "rf_model = RandomForestRegressor(\n",
    "    max_depth=10,\n",
    "    max_features='log2',\n",
    "    min_samples_leaf=2,\n",
    "    n_estimators=500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the Random Forest model on the training set\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training and test sets\n",
    "rf_train_pred = rf_model.predict(X_train)\n",
    "rf_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE and R^2 for the Random Forest model on the training set\n",
    "rf_train_rmse = mean_squared_error(y_train, rf_train_pred, squared=False)\n",
    "rf_train_r2 = r2_score(y_train, rf_train_pred)\n",
    "\n",
    "# Calculate RMSE and R^2 for the Random Forest model on the test set\n",
    "rf_test_rmse = mean_squared_error(y_test, rf_test_pred, squared=False)\n",
    "rf_test_r2 = r2_score(y_test, rf_test_pred)\n",
    "\n",
    "# Print the evaluation metrics for the Random Forest model\n",
    "print(\"Random Forest - Training RMSE:\", rf_train_rmse)\n",
    "print(\"Random Forest - Training R^2:\", rf_train_r2)\n",
    "print(\"Random Forest - Test RMSE:\", rf_test_rmse)\n",
    "print(\"Random Forest - Test R^2:\", rf_test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot with fitted line for training and test data (for Linear Regression)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_train, rf_train_pred, color='blue', label='Training Data')\n",
    "plt.scatter(y_test, rf_test_pred, color='red', label='Test Data')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted (Random Forest)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the Random Forest model\n",
    "feature_importance = rf_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature names and their importance values\n",
    "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})\n",
    "\n",
    "# Sort the DataFrame by importance values in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
